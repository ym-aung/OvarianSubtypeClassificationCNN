{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "#ORIGINAL_THUMBNAIL_FOLDER_PATH = Path(\".\\\\train_thumbnails\")\n",
        "PROCESSED_THUMBNAIL_FOLDER_PATH = Path(\"/Users/ryan/Downloads/TF_data/processed_train_thumbnails\")\n",
        "\n",
        "RESIZE_WIDTH = 64\n",
        "RESIZE_HEIGHT = 64\n",
        "\n",
        "# Resize all images to the same dimensions\n",
        "\n",
        "for thumbnail_path in PROCESSED_THUMBNAIL_FOLDER_PATH.iterdir():\n",
        "    img = Image.open(os.path.join(\".\", thumbnail_path))\n",
        "\n",
        "    new_img = img.resize((RESIZE_WIDTH, RESIZE_HEIGHT))\n",
        "\n",
        "    new_img.save(os.path.join(PROCESSED_THUMBNAIL_FOLDER_PATH, os.path.basename(thumbnail_path)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import os.path\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "\n",
        "label_to_num_dict = {\n",
        "    \"HGSC\": 0,\n",
        "    \"LGSC\": 1,\n",
        "    \"EC\": 2,\n",
        "    \"CC\": 3,\n",
        "    \"MC\": 4\n",
        "}\n",
        "\n",
        "image_id_list = []\n",
        "label_list = []\n",
        "\n",
        "with open(\"train.csv\", newline=\"\") as csvfile:\n",
        "  fileReader = csv.DictReader(csvfile, delimiter=\",\")\n",
        "  for row in fileReader:\n",
        "    if row[\"is_tma\"] == \"False\":\n",
        "      image_id_list.append(row[\"image_id\"])\n",
        "      label_list.append(label_to_num_dict[row[\"label\"]])\n",
        "#HGSC, LGSC, E, C, M\n",
        "\n",
        "class_weights = []\n",
        "for i in range(5):\n",
        "  class_weights.append(len(label_list)/(label_list.count(i)*5))\n",
        "class_weights = torch.FloatTensor(class_weights)\n",
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, image_id_list, label_list, train_index):\n",
        "    self.x_data = []\n",
        "    self.y_data = []\n",
        "\n",
        "    transform = A.Compose([A.ToFloat(), ToTensorV2()])\n",
        "\n",
        "    for i in train_index:\n",
        "      img = np.array(Image.open(os.path.join(\"processed_train_thumbnails\", f\"{image_id_list[i]}_thumbnail.png\")))\n",
        "      self.x_data.append(transform(image=img))\n",
        "      self.y_data.append(label_list[i])\n",
        "\n",
        "\n",
        "    self.len = len(self.x_data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x_data[index], self.y_data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "class RotateImageDataset(Dataset):\n",
        "    def __init__(self, image_id_list, label_list, train_index):\n",
        "        self.x_data = []\n",
        "        self.y_data = []\n",
        "\n",
        "        transform = A.Compose([\n",
        "            A.Rotate(limit=30),\n",
        "            A.ToFloat(),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "        for i in train_index:\n",
        "            img = np.array(Image.open(os.path.join(\"processed_train_thumbnails\", f\"{image_id_list[i]}_thumbnail.png\")))\n",
        "            augmented_img = transform(image=img)['image']\n",
        "            self.x_data.append(augmented_img)\n",
        "            self.y_data.append(label_list[i])\n",
        "\n",
        "        self.len = len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "class VFlippedImageDataset(Dataset):\n",
        "    def __init__(self, image_id_list, label_list, train_index):\n",
        "        self.x_data = []\n",
        "        self.y_data = []\n",
        "\n",
        "        transform = A.Compose([\n",
        "            A.ToFloat(),\n",
        "            A.VerticalFlip(p=0.9),  # Add horizontal flip with 50% probability\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "        for i in train_index:\n",
        "            img = np.array(Image.open(os.path.join(\"processed_train_thumbnails\", f\"{image_id_list[i]}_thumbnail.png\")))\n",
        "            augmented_img = transform(image=img)['image']\n",
        "            self.x_data.append(augmented_img)\n",
        "            self.y_data.append(label_list[i])\n",
        "\n",
        "        self.len = len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.convlayer1 = nn.Conv2d(3, 32, kernel_size=(5, 5), stride=1, padding=1)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        self.convlayer2 = nn.Conv2d(32, 32, kernel_size=(5, 5), stride=1, padding=1)\n",
        "        self.layer1 = nn.Linear(28800, 512)\n",
        "        self.fc = nn.Linear(512, 5)\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.convlayer1(X)\n",
        "        out = nn.functional.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.convlayer2(out)\n",
        "        out = nn.functional.relu(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = torch.flatten(out, start_dim=1)\n",
        "        out = self.layer1(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def reset_weights(m):\n",
        "  for i in m.children():\n",
        "    if hasattr(i, 'reset_parameters'):\n",
        "      i.reset_parameters()\n",
        "model = CNNModel()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
        "\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 15\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "num_folds = 15\n",
        "kFold = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
        "splits = kFold.split(image_id_list, label_list)\n",
        "num_epochs = 15\n",
        "\n",
        "results = {}\n",
        "scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=5, min_lr=1e-6)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold # 0, Epoch [1/15], Step [10/15], Loss: 2.1792\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "too many indices for tensor of dimension 4",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/Users/ryan/Downloads/TF_data/proj.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ryan/Downloads/TF_data/proj.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ryan/Downloads/TF_data/proj.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ryan/Downloads/TF_data/proj.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m output \u001b[39m=\u001b[39m model(x_imgs[\u001b[39m\"\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ryan/Downloads/TF_data/proj.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ryan/Downloads/TF_data/proj.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Backward and optimize\u001b[39;00m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 4"
          ]
        }
      ],
      "source": [
        "for n,(train_index,test_index) in enumerate(splits):\n",
        "  dataset_train = ImageDataset(image_id_list, label_list, train_index)\n",
        "  dataset_train_hflipped = RotateImageDataset(image_id_list, label_list, train_index)\n",
        "  dataset_train_vflipped = VFlippedImageDataset(image_id_list, label_list, train_index)\n",
        "\n",
        "  dataset_test = ImageDataset(image_id_list, label_list, test_index)\n",
        "\n",
        "  train_loader = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True)\n",
        "  hflipped_train_loader = DataLoader(dataset=dataset_train_hflipped, batch_size=32, shuffle=True)\n",
        "  vflipped_train_loader = DataLoader(dataset=dataset_train_vflipped, batch_size=32, shuffle=True)\n",
        "\n",
        "  test_loader = DataLoader(dataset=dataset_test, batch_size=32, shuffle=True)\n",
        "\n",
        "  #model = CNNModel()\n",
        "  model.apply(reset_weights)\n",
        "\n",
        "  total_step = len(train_loader)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    current_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "      x_imgs, labels = data\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      output = model(x_imgs[\"image\"])\n",
        "      loss = criterion(output, labels)\n",
        "\n",
        "      # Backward and optimize\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step(current_loss)\n",
        "\n",
        "      current_loss += loss.item()\n",
        "      #_, predicted = torch.max(output.data, 1)\n",
        "      #print('Predictions for batch {}: {}'.format(i + 1, predicted))\n",
        "      if (i+1) % 10 == 0:\n",
        "        print ('Fold # {}, Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                .format(n, epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "  correct, all = 0,0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "      x_imgs, labels = data\n",
        "\n",
        "      output = model(x_imgs[\"image\"])\n",
        "\n",
        "      _, predicted  = torch.max(output.data, 1)\n",
        "      print(\"LABELS: \", labels)\n",
        "      print('PREDICTED :', predicted)\n",
        "      all += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print accuracy\n",
        "    print('Accuracy for fold %d: %d %%' % (n, 100.0 * correct / all))\n",
        "    print('--------------------------------')\n",
        "    results[n] = 100.0 * (correct / all)\n",
        "\n",
        "# Print fold results\n",
        "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {num_folds} FOLDS')\n",
        "print('--------------------------------')\n",
        "sum = 0.0\n",
        "for key, value in results.items():\n",
        "  print(f'Fold {key}: {value} %')\n",
        "  sum += value\n",
        "print(f'Average: {sum/len(results.items())} %')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "TF_motif_prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
